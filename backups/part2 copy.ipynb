{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pymonntorch import (\n",
    "    NeuronGroup,\n",
    "    NeuronDimension,\n",
    "    EventRecorder,\n",
    "    Recorder,\n",
    "    SynapseGroup,\n",
    ")\n",
    "from conex import (\n",
    "    Neocortex,\n",
    "    NeuronAxon,\n",
    "    SpikeTrace,\n",
    "    SimpleDendriteComputation,\n",
    "    SimpleDendriteStructure,\n",
    "    LIF,\n",
    ")\n",
    "from conex import (\n",
    "    Synapsis,\n",
    "    SynapseInit,\n",
    "    WeightInitializer,\n",
    "    Conv2dDendriticInput,\n",
    "    Conv2dSTDP,\n",
    "    prioritize_behaviors,\n",
    "    Fire,\n",
    ")\n",
    "from conex import ActivityBaseHomeostasis, KWTA, LateralDendriticInput\n",
    "from conex.helpers import Poisson\n",
    "import conex.helpers.filters as filters\n",
    "\n",
    "from conex.behaviors.synapses import (\n",
    "    SynapseInit,\n",
    "    WeightInitializer,\n",
    "    WeightNormalization,\n",
    ")\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import behaviors.InputData as InputData\n",
    "from tools.convolutions import convolve, convolve3d, batch_convolve\n",
    "import tools.readImage as readImage\n",
    "\n",
    "from plots.model import *\n",
    "\n",
    "from tools.encode import encode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input parameters\n",
    "INPUT_HEIGHT, INPUT_WIDTH = 100, 100\n",
    "\n",
    "# behavior parameters\n",
    "RECORDER_INDEX = 460\n",
    "EV_RECORDER_INDEX = 461\n",
    "\n",
    "# LIF parameters\n",
    "OUT_R = 10\n",
    "OUT_THRESHOLD = 15\n",
    "OUT_TAU = 3\n",
    "OUT_V_RESET = 0\n",
    "OUT_V_REST = 5\n",
    "\n",
    "# Model parameters\n",
    "T = 990\n",
    "f, INPUT_CHANNELS, KERNEL_HEIGHT, KERNEL_WIDTH = 9, 1, INPUT_HEIGHT, INPUT_WIDTH\n",
    "ACTIVITY_RATE = 0.2\n",
    "WINDOW_SIZE = 10\n",
    "K, DIMENSION = 1, 0\n",
    "I_TAU = 4\n",
    "LI_D, LI_H, LI_W = f, 5, 5\n",
    "LI_CURRENT = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(\n",
    "    data_rng=range(1, 10),\n",
    "    sigma_1=10 / 15,\n",
    "    sigma_2=3 / 15,\n",
    "    one_sum=True,\n",
    "    show_images=False,\n",
    "    sizes=[3, 7, 11],\n",
    "):\n",
    "\n",
    "    size1 = sizes[0]\n",
    "    f1 = torch.tensor(\n",
    "        filters.DoGFilter(\n",
    "            size1, sigma_1=size1 * 10 / 15, sigma_2=size1 * 3 / 15, one_sum=True\n",
    "        ),\n",
    "    )\n",
    "    f1 = f1 / (torch.abs(f1)).max()\n",
    "\n",
    "    size2 = sizes[1]\n",
    "    f2 = torch.tensor(\n",
    "        filters.DoGFilter(\n",
    "            size2, sigma_1=size2 * 10 / 15, sigma_2=size2 * 3 / 15, one_sum=True\n",
    "        ),\n",
    "    )\n",
    "    f2 = f2 / (torch.abs(f2)).max()\n",
    "\n",
    "    size3 = sizes[2]\n",
    "    f3 = torch.tensor(\n",
    "        filters.DoGFilter(\n",
    "            size3, sigma_1=size3 * 10 / 15, sigma_2=size3 * 3 / 15, one_sum=True\n",
    "        ),\n",
    "    )\n",
    "    f3 = f3 / (torch.abs(f3)).max()\n",
    "\n",
    "    temp = [\n",
    "        convolve(\n",
    "            f\"0{i}.png\",\n",
    "            # useTorch=True,\n",
    "            prefix=\"./images/\",\n",
    "            n=INPUT_HEIGHT,\n",
    "            show_image=show_images,\n",
    "            filter=filter,\n",
    "            flatten=True,\n",
    "            return_both=True,\n",
    "        )\n",
    "        for filter in [f1, f2, f3]\n",
    "        for i in data_rng\n",
    "    ]\n",
    "    data = []\n",
    "    for d in temp:\n",
    "        data += d\n",
    "\n",
    "    return {\n",
    "        \"data\": data,\n",
    "        \"parameters\": [\n",
    "            {\n",
    "                f\"f{size1}_size\": size1,\n",
    "                f\"f{size1}_sigma_1\": size1 * 10 / 15,\n",
    "                f\"f{size1}_sigma_2\": size1 * 3 / 15,\n",
    "            },\n",
    "            {\n",
    "                f\"f{size2}_size\": size2,\n",
    "                f\"f{size2}_sigma_1\": size2 * 10 / 15,\n",
    "                f\"f{size2}_sigma_2\": size2 * 3 / 15,\n",
    "            },\n",
    "            {\n",
    "                f\"f{size3}_size\": size3,\n",
    "                f\"f{size3}_sigma_1\": size3 * 10 / 15,\n",
    "                f\"f{size3}_sigma_2\": size3 * 3 / 15,\n",
    "            },\n",
    "        ],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/58/7wqv58ns32s3g7d1404b7mmw0000gn/T/ipykernel_11525/3001344719.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  f1 = torch.tensor(\n",
      "/var/folders/58/7wqv58ns32s3g7d1404b7mmw0000gn/T/ipykernel_11525/3001344719.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  f2 = torch.tensor(\n",
      "/var/folders/58/7wqv58ns32s3g7d1404b7mmw0000gn/T/ipykernel_11525/3001344719.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  f3 = torch.tensor(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['f3_size: 3', 'f3_sigma_1: 2.0', 'f3_sigma_2: 0.6', 'f7_size: 7', 'f7_sigma_1: 4.666666666666667', 'f7_sigma_2: 1.4', 'f11_size: 11', 'f11_sigma_1: 7.333333333333333', 'f11_sigma_2: 2.2']\n"
     ]
    }
   ],
   "source": [
    "data, temp_parameters = prepare_data(\n",
    "    show_images=False, data_rng=range(1, f + 1)\n",
    ").values()\n",
    "parameters = []\n",
    "for d in temp_parameters:\n",
    "    for item in d:\n",
    "        parameters.append(f\"{item}: {d[item]}\")\n",
    "print(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/58/7wqv58ns32s3g7d1404b7mmw0000gn/T/ipykernel_11525/3001344719.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  f1 = torch.tensor(\n",
      "/var/folders/58/7wqv58ns32s3g7d1404b7mmw0000gn/T/ipykernel_11525/3001344719.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  f2 = torch.tensor(\n",
      "/var/folders/58/7wqv58ns32s3g7d1404b7mmw0000gn/T/ipykernel_11525/3001344719.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  f3 = torch.tensor(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['f3_size: 3', 'f3_sigma_1: 2.0', 'f3_sigma_2: 0.6', 'f5_size: 5', 'f5_sigma_1: 3.3333333333333335', 'f5_sigma_2: 1.0', 'f7_size: 7', 'f7_sigma_1: 4.666666666666667', 'f7_sigma_2: 1.4']\n"
     ]
    }
   ],
   "source": [
    "data, temp_parameters = prepare_data(\n",
    "    show_images=False, data_rng=range(1, f + 1), sizes=[3, 5, 7]\n",
    ").values()\n",
    "parameters = []\n",
    "for d in temp_parameters:\n",
    "    for item in d:\n",
    "        parameters.append(f\"{item}: {d[item]}\")\n",
    "print(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['f3_size: 3', 'f3_sigma_1: 2.0', 'f3_sigma_2: 0.6', 'f5_size: 5', 'f5_sigma_1: 3.3333333333333335', 'f5_sigma_2: 1.0', 'f7_size: 7', 'f7_sigma_1: 4.666666666666667', 'f7_sigma_2: 1.4']\n"
     ]
    }
   ],
   "source": [
    "print(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plots.gifMaker as gif\n",
    "\n",
    "\n",
    "def train(\n",
    "    data,\n",
    "    height=INPUT_HEIGHT,\n",
    "    width=INPUT_WIDTH,\n",
    "    iterations=T,\n",
    "    OUT_R=OUT_R,\n",
    "    OUT_THRESHOLD=OUT_THRESHOLD,\n",
    "    OUT_TAU=OUT_TAU,\n",
    "    OUT_V_RESET=OUT_V_RESET,\n",
    "    OUT_V_REST=OUT_V_REST,\n",
    "    input_channels=INPUT_CHANNELS,\n",
    "    kernel_height=KERNEL_HEIGHT,\n",
    "    kernel_width=KERNEL_WIDTH,\n",
    "    f=f,\n",
    "    activity_rate=ACTIVITY_RATE,\n",
    "    window_siz=WINDOW_SIZE,\n",
    "    encode_method=\"ITL\",\n",
    "    show_weights=True,\n",
    "    show_last_spike=True,\n",
    "    show_mean_spike=True,\n",
    "    show_result_spike=True,\n",
    "    show_activity=False,\n",
    "    feature_gif_skip_frame=10,\n",
    "    rest_time=10,\n",
    "    weight_mode=\"ones\",\n",
    "    AP=2,\n",
    "    AM=1,\n",
    "    K=K,\n",
    "    s=0.1,\n",
    "):\n",
    "\n",
    "    layer2_height, layer2_width = (\n",
    "        height - kernel_height + 1,\n",
    "        width - kernel_width + 1,\n",
    "    )\n",
    "    net = Neocortex(dt=1, device=\"cpu\", dtype=torch.float32)\n",
    "    ng1 = NeuronGroup(\n",
    "        size=NeuronDimension(height=height, width=width),\n",
    "        behavior={\n",
    "            **prioritize_behaviors(\n",
    "                [\n",
    "                    SimpleDendriteStructure(),\n",
    "                    SimpleDendriteComputation(),\n",
    "                    LIF(\n",
    "                        R=OUT_R,\n",
    "                        threshold=OUT_THRESHOLD,\n",
    "                        tau=OUT_TAU,\n",
    "                        v_reset=OUT_V_RESET,\n",
    "                        v_rest=OUT_V_REST,\n",
    "                    ),  # 260\n",
    "                    Fire(),  # 340\n",
    "                    SpikeTrace(tau_s=3),\n",
    "                    NeuronAxon(),\n",
    "                ]\n",
    "            ),\n",
    "            **{\n",
    "                10: InputData.ResetMemory(),\n",
    "                345: InputData.Encode(\n",
    "                    data=torch.tensor(data),\n",
    "                    # range=255,\n",
    "                    time=window_siz,\n",
    "                    sparsity=1,\n",
    "                    input_period=window_siz + rest_time,\n",
    "                    ratio=0.05,\n",
    "                    method=encode_method,\n",
    "                ),\n",
    "                # 350: act.Activity(),\n",
    "                RECORDER_INDEX: Recorder(\n",
    "                    variables=[\"v\", \"I\"],\n",
    "                    tag=\"in_recorder\",\n",
    "                ),\n",
    "                EV_RECORDER_INDEX: EventRecorder(\"spikes\", tag=\"in_ev_recorder\"),\n",
    "            },\n",
    "        },\n",
    "        net=net,\n",
    "    )\n",
    "\n",
    "    ng2 = NeuronGroup(\n",
    "        size=NeuronDimension(depth=f, height=layer2_height, width=layer2_width),\n",
    "        net=net,\n",
    "        behavior={\n",
    "            **prioritize_behaviors(\n",
    "                [\n",
    "                    SimpleDendriteStructure(),\n",
    "                    SimpleDendriteComputation(),\n",
    "                    LIF(\n",
    "                        tau=10,\n",
    "                        v_rest=0,\n",
    "                        v_reset=0,\n",
    "                        threshold=1,\n",
    "                        R=1,\n",
    "                    ),\n",
    "                    KWTA(k=K, dimension=0),\n",
    "                    Fire(),\n",
    "                    SpikeTrace(tau_s=10.0),\n",
    "                    NeuronAxon(),\n",
    "                    # ActivityBaseHomeostasis(\n",
    "                    #     activity_rate=activity_rate * window_siz,\n",
    "                    #     window_size=(window_siz + rest_time)*f,\n",
    "                    #     updating_rate=0.1,\n",
    "                    #     decay_rate=0.2,\n",
    "                    # ),\n",
    "                    ActivityBaseHomeostasis(\n",
    "                        activity_rate=activity_rate * window_siz,\n",
    "                        window_size=(window_siz + rest_time),\n",
    "                        updating_rate=0.1,\n",
    "                    ),\n",
    "                ]\n",
    "            ),\n",
    "            **{\n",
    "                RECORDER_INDEX: Recorder(variables=[\"spikes\"], tag=\"out_recorder\"),\n",
    "                EV_RECORDER_INDEX: EventRecorder(\n",
    "                    variables=[\"I\", \"spikes\"], tag=\"out_ev_recorder\"\n",
    "                ),\n",
    "            },\n",
    "        },\n",
    "    )\n",
    "    synapse_input_layer2 = Synapsis(\n",
    "        net=net,\n",
    "        src=ng1,\n",
    "        dst=ng2,\n",
    "        synaptic_tag=\"Proximal\",\n",
    "        synapsis_behavior={\n",
    "            **prioritize_behaviors(\n",
    "                [\n",
    "                    SynapseInit(),\n",
    "                    WeightNormalization(),\n",
    "                    WeightInitializer(\n",
    "                        mode=weight_mode,\n",
    "                        scale=5,\n",
    "                        weight_shape=(f, input_channels, kernel_height, kernel_width),\n",
    "                        kernel_shape=(f, input_channels, kernel_height, kernel_width),\n",
    "                    ),\n",
    "                    Conv2dDendriticInput(\n",
    "                        # current_coef=1 * (kernel_height * kernel_width)\n",
    "                        current_coef= 20,\n",
    "                    ),\n",
    "                    Conv2dSTDP(\n",
    "                        a_plus=AP * (kernel_height * kernel_width),\n",
    "                        a_minus=AM * (kernel_height * kernel_width),\n",
    "                        w_max=2 / (kernel_height * kernel_width),\n",
    "                        positive_bound=\"soft_bound\",\n",
    "                        negative_bound=\"soft_bound\",\n",
    "                    ),\n",
    "                ]\n",
    "            ),\n",
    "            **{\n",
    "                RECORDER_INDEX: Recorder(tag=\"synapse_recorder\", variables=[\"weights\"]),\n",
    "            },\n",
    "        },\n",
    "    )\n",
    "\n",
    "    lateral_inhibition = Synapsis(\n",
    "        net=net,\n",
    "        src=ng2,\n",
    "        dst=ng2,\n",
    "        synaptic_tag=\"Proximal\",\n",
    "        synapsis_behavior=prioritize_behaviors(\n",
    "            [\n",
    "                SynapseInit(),\n",
    "                WeightInitializer(\n",
    "                    mode=\"ones\",\n",
    "                    scale=0.5,\n",
    "                    weight_shape=(1, 1, 2 * f + 1, 1, 1),\n",
    "                    kernel_shape=(1, 1, 2 * f + 1, 1, 1),\n",
    "                ),\n",
    "                LateralDendriticInput(inhibitory=True, current_coef=1000),\n",
    "            ]\n",
    "        ),\n",
    "    )\n",
    "    net.initialize(info=False)\n",
    "    net.simulate_iterations(iterations)\n",
    "    spikes = ng2.spikes.reshape(f, layer2_height, layer2_width)\n",
    "    # spikes = ng2.spikes\n",
    "    if show_activity:\n",
    "        plt.scatter(\n",
    "            ng1[\"in_ev_recorder\", 0].variables[\"spikes\"][:, 0].cpu(),\n",
    "            ng1[\"in_ev_recorder\", 0].variables[\"spikes\"][:, 1].cpu(),\n",
    "            s=s,\n",
    "        )\n",
    "        plt.show()\n",
    "\n",
    "        plt.scatter(\n",
    "            ng2[\"out_ev_recorder\", 0].variables[\"spikes\"][:, 0].cpu(),\n",
    "            ng2[\"out_ev_recorder\", 0].variables[\"spikes\"][:, 1].cpu(),\n",
    "            s=s,\n",
    "        )\n",
    "        plt.show()\n",
    "\n",
    "    # print (synapse_input_layer2.weights.shape)\n",
    "    if show_weights:\n",
    "        plot_grid(\n",
    "            synapse_input_layer2.synapses[0].weights.reshape(\n",
    "                f, kernel_height, kernel_width\n",
    "            ),\n",
    "            f=f,\n",
    "        )\n",
    "        print(synapse_input_layer2.synapses[0].weights.reshape(\n",
    "                f, kernel_height, kernel_width\n",
    "            ))\n",
    "    if feature_gif_skip_frame:\n",
    "        print(\n",
    "            synapse_input_layer2.synapses[0][RECORDER_INDEX, 0]\n",
    "            .variables[\"weights\"]\n",
    "            .shape\n",
    "        )\n",
    "        weights = (\n",
    "            synapse_input_layer2.synapses[0][RECORDER_INDEX, 0]\n",
    "            .variables[\"weights\"]\n",
    "            .reshape(iterations, f, kernel_height, kernel_width)\n",
    "        )\n",
    "        gif.generate(\n",
    "            weights,\n",
    "            skip_frame=feature_gif_skip_frame,\n",
    "            title=f\"Features {kernel_height}*{kernel_width}\",\n",
    "        )\n",
    "\n",
    "        spikes = (\n",
    "            ng2[RECORDER_INDEX, 0]\n",
    "            .variables[\"spikes\"]\n",
    "            .reshape(iterations, f, layer2_height, layer2_width)\n",
    "        )\n",
    "        gif.generate(\n",
    "            spikes,\n",
    "            skip_frame=feature_gif_skip_frame,\n",
    "            title=f\"Spikes {kernel_height}*{kernel_width}\",\n",
    "        )\n",
    "\n",
    "    if show_last_spike:\n",
    "        spikes = ng2.spikes.reshape(f, layer2_height, layer2_width)\n",
    "        plot_grid(spikes, f=f, title=\"Last spikes\")\n",
    "\n",
    "    if show_mean_spike:\n",
    "        spikes = (\n",
    "            ng2[RECORDER_INDEX, 0]\n",
    "            .variables[\"spikes\"]\n",
    "            .reshape(iterations, f, layer2_height, layer2_width)\n",
    "        )\n",
    "        spikes = spikes.sum(axis=0, keepdim=True)[0]\n",
    "        plot_grid(spikes, f=f, title=\"Mean of spikes\")\n",
    "    if show_result_spike:\n",
    "        for i in range(f):\n",
    "\n",
    "            spikes = (\n",
    "                ng2[RECORDER_INDEX, 0]\n",
    "                .variables[\"spikes\"]\n",
    "                .reshape(iterations, f, layer2_height, layer2_width)[\n",
    "                    -(window_siz + rest_time) * (i + 1) : -(window_siz + rest_time) * i\n",
    "                ]\n",
    "            )\n",
    "            spikes = spikes.sum(axis=0, keepdim=True)[0]\n",
    "            plot_grid(spikes, f=f, title=\"Convolution Result\")\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m net \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43miterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrest_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwindow_siz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mactivity_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_last_spike\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_mean_spike\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_gif_skip_frame\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mAP\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.02\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mAM\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 174\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(data, height, width, iterations, OUT_R, OUT_THRESHOLD, OUT_TAU, OUT_V_RESET, OUT_V_REST, input_channels, kernel_height, kernel_width, f, activity_rate, window_siz, encode_method, show_weights, show_last_spike, show_mean_spike, show_result_spike, show_activity, feature_gif_skip_frame, rest_time, weight_mode, AP, AM, K, s)\u001b[0m\n\u001b[1;32m    121\u001b[0m synapse_input_layer2 \u001b[38;5;241m=\u001b[39m Synapsis(\n\u001b[1;32m    122\u001b[0m     net\u001b[38;5;241m=\u001b[39mnet,\n\u001b[1;32m    123\u001b[0m     src\u001b[38;5;241m=\u001b[39mng1,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    153\u001b[0m     },\n\u001b[1;32m    154\u001b[0m )\n\u001b[1;32m    156\u001b[0m lateral_inhibition \u001b[38;5;241m=\u001b[39m Synapsis(\n\u001b[1;32m    157\u001b[0m     net\u001b[38;5;241m=\u001b[39mnet,\n\u001b[1;32m    158\u001b[0m     src\u001b[38;5;241m=\u001b[39mng2,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    172\u001b[0m     ),\n\u001b[1;32m    173\u001b[0m )\n\u001b[0;32m--> 174\u001b[0m \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43minfo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m net\u001b[38;5;241m.\u001b[39msimulate_iterations(iterations)\n\u001b[1;32m    176\u001b[0m spikes \u001b[38;5;241m=\u001b[39m ng2\u001b[38;5;241m.\u001b[39mspikes\u001b[38;5;241m.\u001b[39mreshape(f, layer2_height, layer2_width)\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Me/University/Term 8/CNS/HomeWork/CNSVEnv/lib/python3.11/site-packages/pymonntorch/NetworkCore/Network.py:194\u001b[0m, in \u001b[0;36mNetwork.initialize\u001b[0;34m(self, info, warnings, storage_manager)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m storage_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    192\u001b[0m         storage_manager\u001b[38;5;241m.\u001b[39msave_param(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfo\u001b[39m\u001b[38;5;124m\"\u001b[39m, desc)\n\u001b[0;32m--> 194\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize_behaviors\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_unique_tags(warnings)\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfill_substructures()\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Me/University/Term 8/CNS/HomeWork/CNSVEnv/lib/python3.11/site-packages/pymonntorch/NetworkCore/Network.py:201\u001b[0m, in \u001b[0;36mNetwork.initialize_behaviors\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, parent, behavior \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msorted_behavior_execution_list:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m behavior\u001b[38;5;241m.\u001b[39minitialize_on_init \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m behavior\u001b[38;5;241m.\u001b[39minitialize_last:\n\u001b[0;32m--> 201\u001b[0m         \u001b[43mbehavior\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m         behavior\u001b[38;5;241m.\u001b[39mcheck_unused_attrs()\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, parent, behavior \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msorted_behavior_execution_list:\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Me/University/Term 8/CNS/HomeWork/CNSVEnv/lib/python3.11/site-packages/conex/behaviors/neurons/homeostasis.py:37\u001b[0m, in \u001b[0;36mActivityBaseHomeostasis.initialize\u001b[0;34m(self, neurons)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecay_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecay_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfiring_reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnon_firing_penalty \u001b[38;5;241m=\u001b[39m \u001b[38;5;241;43m-\u001b[39;49m\u001b[43mactivity_rate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwindow_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mactivity_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivities \u001b[38;5;241m=\u001b[39m neurons\u001b[38;5;241m.\u001b[39mvector(mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "net = train(\n",
    "    data,\n",
    "    iterations=1000,\n",
    "    rest_time=0,\n",
    "    window_siz=5,\n",
    "    activity_rate=0.1,\n",
    "    show_last_spike=False,\n",
    "    show_mean_spike=False,\n",
    "    feature_gif_skip_frame=0,\n",
    "    AP=0.02,\n",
    "    AM=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = train(\n",
    "    data,\n",
    "    iterations=1000,\n",
    "    activity_rate=0.3,\n",
    "    feature_gif_skip_frame=0,\n",
    "    show_last_spike=False,\n",
    "    show_mean_spike=False,\n",
    "    AP=0.01,\n",
    "    AM=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = train(\n",
    "    data,\n",
    "    iterations=1000,\n",
    "    feature_gif_skip_frame=0,\n",
    "    rest_time=0,\n",
    "    window_siz=5,\n",
    "    kernel_height=9,\n",
    "    kernel_width=9,\n",
    "    activity_rate=0.1,\n",
    "    AP=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = train(\n",
    "    data,\n",
    "    iterations=1000,\n",
    "    feature_gif_skip_frame=0,\n",
    "    rest_time=0,\n",
    "    window_siz=10,\n",
    "    kernel_height=9,\n",
    "    kernel_width=9,\n",
    "    activity_rate=1,\n",
    "    AM=1,\n",
    "    AP=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = train(\n",
    "    data,\n",
    "    iterations=1000,\n",
    "    rest_time=1,\n",
    "    window_siz=2,\n",
    "    feature_gif_skip_frame=0,\n",
    "    kernel_height=7,\n",
    "    kernel_width=7,\n",
    "    activity_rate=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = train(\n",
    "    data,\n",
    "    iterations=1000,\n",
    "    activity_rate=0.2,\n",
    "    rest_time=2,\n",
    "    window_siz=2,\n",
    "    feature_gif_skip_frame=10,\n",
    "    show_last_spike=False,\n",
    "    show_mean_spike=False,\n",
    "    AP=0.2,\n",
    "    AM=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = train(\n",
    "    data,\n",
    "    iterations=1000,\n",
    "    activity_rate=0.2,\n",
    "    rest_time=5,\n",
    "    window_siz=2,\n",
    "    kernel_height=15,\n",
    "    kernel_width=15,\n",
    "    feature_gif_skip_frame=10,\n",
    "    show_last_spike=False,\n",
    "    show_mean_spike=False,\n",
    "    AP=2,\n",
    "    AM=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = train(\n",
    "    data,\n",
    "    iterations=1000,\n",
    "    activity_rate=0.2,\n",
    "    rest_time=5,\n",
    "    window_siz=2,\n",
    "    kernel_height=11,\n",
    "    kernel_width=11,\n",
    "    feature_gif_skip_frame=10,\n",
    "    show_last_spike=False,\n",
    "    show_mean_spike=False,\n",
    "    AP=2,\n",
    "    AM=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = train(\n",
    "    data,\n",
    "    iterations=1000,\n",
    "    activity_rate=0.2,\n",
    "    rest_time=5,\n",
    "    window_siz=2,\n",
    "    kernel_height=5,\n",
    "    kernel_width=5,\n",
    "    feature_gif_skip_frame=10,\n",
    "    show_last_spike=False,\n",
    "    show_mean_spike=False,\n",
    "    AP=2,\n",
    "    AM=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = train(\n",
    "    data,\n",
    "    iterations=1000,\n",
    "    activity_rate=0.2,\n",
    "    rest_time=5,\n",
    "    window_siz=2,\n",
    "    kernel_height=21,\n",
    "    kernel_width=21,\n",
    "    feature_gif_skip_frame=10,\n",
    "    show_last_spike=False,\n",
    "    show_mean_spike=False,\n",
    "    AP=2,\n",
    "    AM=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = train(\n",
    "    data,\n",
    "    iterations=1000,\n",
    "    window_siz=2,\n",
    "    rest_time=1,\n",
    "    activity_rate=0.1,\n",
    "    show_last_spike=False,\n",
    "    show_mean_spike=False,\n",
    "    feature_gif_skip_frame=0,\n",
    "    AP=0.2,\n",
    "    AM=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = train(\n",
    "    data,\n",
    "    iterations=1000,\n",
    "    activity_rate=0.25,\n",
    "    rest_time=10,\n",
    "    window_siz=0,\n",
    "    kernel_height=35,\n",
    "    kernel_width=35,\n",
    "    feature_gif_skip_frame=10,\n",
    "    show_last_spike=False,\n",
    "    show_mean_spike=False,\n",
    "    AP=0.75,\n",
    "    AM=0.75,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CNSVEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
